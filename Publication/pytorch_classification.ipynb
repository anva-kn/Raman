{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-image tqdm torchmetrics astropy torch-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Learning Notebook  \n",
    "# PCA, Classification\n",
    "1 - Carbendazim  \n",
    "2 - Thiacloprid  \n",
    "4 - Acetamiprid   \n",
    "Mixtures of the above mentioned analytes\n",
    "\n",
    "Batch 3 of the colloids was chosen for all of the recordings due to the superior signal intensity that it showed.  \n",
    "\n",
    "Mixtures 2 + 4 and 1 + 2 + 4 are different from all of the other data. Integration time was changed from 500ms to 1500ms due to insufficient strength of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ramanflow.read_data import ReadData as rd\n",
    "from tools.ramanflow.prep_data import PrepData as rpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "The naming convention here as follows: NameOfAnalyte_BatchNo_ColloidsReductionSpeed_TypeOfReading  \n",
    "**NameOfAnalyte**: 1 = car, 2 = thia, 4 = aceta  \n",
    "**BatchNo**: Here it gets a bit tricky. The batch of colloids is the same in all of the measurements. However we splitted the acquisition into 3 separate recodrings to have a bit of variation within the batch. So the colloids that were used are all from the same batch.  \n",
    "**CollidsReductionSpeed**: 3min is the time of how long it took to reduce 90ml of HH+NaOH with 10ml of AgNO3. I call it reduction speed for convinience and because it represents the matter more accurately  \n",
    "**TypeOfReading**: Generally speaking there are 2 types of reading. Single spectra acquisition or spectral mapping where multiple spectra acquired. 50X50 means the mapping has 50X50 spectral images each of which corresponds to single spectra. So there are 2500 spectra in one recording.   \n",
    "\n",
    "Total amount of data for each of the analyte and the mixtures is 7500 spectra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Carbendazim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, car_batch1_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1/mapping50X50/1_3min_b3_50X50_spectral_mapping_1.tif\")\n",
    "f_sup, car_batch2_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1/mapping50X50/1_3min_b3_50X50_spectral_mapping_2.tif\")\n",
    "f_sup, car_batch3_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1/mapping50X50/1_3min_b3_50X50_spectral_mapping_3.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Thiacloprid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, thia_batch1_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2/mapping 50X50/2_3min_b3_50X50_spectral_mapping_1.tif\")\n",
    "f_sup, thia_batch2_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2/mapping 50X50/2_3min_b3_50X50_spectral_mapping_2.tif\")\n",
    "f_sup, thia_batch3_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2/mapping 50X50/2_3min_b3_50X50_spectral_mapping_3.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Acetamiprid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, aceta_batch1_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 4/mapping50X50/4_3min_b3_50X50_spectral_mapping_1.tif\")\n",
    "f_sup, aceta_batch2_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 4/mapping50X50/4_3min_b3_50X50_spectral_mapping_2.tif\")\n",
    "f_sup, aceta_batch3_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 4/mapping50X50/4_3min_b3_50X50_spectral_mapping_3.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, car_thia_batch1_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+2/mapping50X50/1+2_3min_b3_50X50_spectral_mapping_1.tif\")\n",
    "f_sup, car_thia_batch2_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+2/mapping50X50/1+2_3min_b3_50X50_spectral_mapping_2.tif\")\n",
    "f_sup, car_thia_batch3_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+2/mapping50X50/1+2_3min_b3_50X50_spectral_mapping_3.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 + 4  \n",
    "\n",
    "**This set of measurements had some problems**  \n",
    "\n",
    "The premixed solution of 1 and 4 that was made on 04/20 and measured on 04/21 showed strong signal.  \n",
    "**However** the premixed solution of 1 and 4 that was made on 04/21 and measured on 04/22 showed no signal at all.  \n",
    "In order to have a data to train on we made a decision to procede with 04/20 solution even though at the time of the experiment it was already 2 days old.  \n",
    "This poses another challenge of the data reproducibility and uniformity. We normally would prefer the experimental condition to stay the same across all measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, car_aceta_batch1_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+4/mapping50X50/1+4(2days)_3min_b3_50X50_spectral_mapping_1.tif\")\n",
    "f_sup, car_aceta_batch2_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+4/mapping50X50/1+4(2days)_3min_b3_50X50_spectral_mapping_2.tif\")\n",
    "f_sup, car_aceta_batch3_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+4/mapping50X50/1+4(2days)_3min_b3_50X50_spectral_mapping_3.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 + 4  \n",
    "\n",
    "As was mentioned before, this particular mixture was having a hard time producing good signal at 500ms integration time. So 1500ms was chosen instead. However the mapping size was reduced to save the time during the acquisition.  \n",
    "\n",
    "**However, recording 6 and 7 had some issues**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, thia_aceta_batch1_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32__1500ms_spectral_mapping_1.tif\")\n",
    "f_sup, thia_aceta_batch2_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32__1500ms_spectral_mapping_2.tif\")\n",
    "f_sup, thia_aceta_batch3_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32__1500ms_spectral_mapping_3.tif\")\n",
    "f_sup, thia_aceta_batch4_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32__1500ms_spectral_mapping_4.tif\")\n",
    "f_sup, thia_aceta_batch5_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32__1500ms_spectral_mapping_5.tif\")\n",
    "f_sup, thia_aceta_batch6_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32_1500ms_spectral_mapping_6(problem).tif\")\n",
    "f_sup, thia_aceta_batch7_3min_mapping = rd.read_data(\"data/20220421 SERS data generation/analyte 2+4/mapping 32X32/2+4_3min_b3_32X32__1500ms_spectral_mapping_7(problem).tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 + 2 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, car_thia_aceta_batch1_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+2+4/mapping32X32/1+2+4_3min_b3_32X32_spectral_mapping_1500ms_1.tif\")\n",
    "f_sup, car_thia_aceta_batch2_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+2+4/mapping32X32/1+2+4_3min_b3_32X32_spectral_mapping_1500ms_2.tif\")\n",
    "f_sup, car_thia_aceta_batch3_3min_mapping = rd.read_data(\"data/20220422 SERS data generation/analyte 1+2+4/mapping32X32/1+2+4_3min_b3_32X32_spectral_mapping_1500ms_3.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15000 ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, mg_15000ppb_1 = rd.read_data(\"data/MG-3 15000ppb 14min/area1.tif\")\n",
    "f_sup, mg_15000ppb_2 = rd.read_data(\"data/MG-3 15000ppb 14min/area2.tif\")\n",
    "f_sup, mg_15000ppb_3 = rd.read_data(\"data/MG-3 15000ppb 14min/area3.tif\")\n",
    "f_sup, mg_15000ppb_4 = rd.read_data(\"data/MG-3 15000ppb 14min/area4.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1500 ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, mg_1500ppb_1 = rd.read_data(\"data/MG-4 1500ppb 0.67h/area1.tif\")\n",
    "f_sup, mg_1500ppb_2 = rd.read_data(\"data/MG-4 1500ppb 0.67h/area2.tif\")\n",
    "f_sup, mg_1500ppb_3 = rd.read_data(\"data/MG-4 1500ppb 0.67h/area3.tif\")\n",
    "f_sup, mg_1500ppb_4 = rd.read_data(\"data/MG-4 1500ppb 0.67h/area4.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150 ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sup, mg_150ppb_1 = rd.read_data(\"data/MG-5 150ppb 1.67h/area1.tif\")\n",
    "f_sup, mg_150ppb_2 = rd.read_data(\"data/MG-5 150ppb 1.67h/area2.tif\")\n",
    "f_sup, mg_150ppb_3 = rd.read_data(\"data/MG-5 150ppb 1.67h/area3.tif\")\n",
    "f_sup, mg_150ppb_4 = rd.read_data(\"data/MG-5 150ppb 1.67h/area4.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting all three batches from each of the analyte into one matrix  \n",
    "\n",
    "**At the same time we remove cosmic rays that may appear in individual spectra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_batch1_no_cosmic_ray = np.zeros_like(car_batch1_3min_mapping)\n",
    "car_batch2_no_cosmic_ray = np.zeros_like(car_batch2_3min_mapping)\n",
    "car_batch3_no_cosmic_ray = np.zeros_like(car_batch3_3min_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_batch1_no_cosmic_ray = np.copy(car_batch1_3min_mapping)\n",
    "car_batch2_no_cosmic_ray = np.copy(car_batch2_3min_mapping)\n",
    "car_batch3_no_cosmic_ray = np.copy(car_batch3_3min_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_batch1_no_cosmic_ray = rpd.remove_cosmic_rays(car_batch1_3min_mapping, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_batch2_no_cosmic_ray = rpd.remove_cosmic_rays(car_batch2_3min_mapping, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_batch3_no_cosmic_ray = rpd.remove_cosmic_rays(car_batch3_3min_mapping, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "268, 1613, 1630, 4747, 5266, 7419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_fuckups = [268, 1613, 1630, 4747, 5266, 7419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_collected_preprocessed = np.zeros((7500, 1430))\n",
    "car_collected_preprocessed[0:2500] = car_batch1_3min_mapping[:, 170:]\n",
    "car_collected_preprocessed[2500:5000] = car_batch2_3min_mapping[:, 170:]\n",
    "car_collected_preprocessed[5000:] = car_batch3_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_collected_preprocessed = rpd.remove_cosmic_rays(car_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_of_fuckups: #len(car_collected_preprocessed)):\n",
    "    plt.plot(f_sup, rpd.remove_cosmic_rays(car_collected_preprocessed[i], 7))\n",
    "    # plt.plot(f_sup, car_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thia_collected_preprocessed = np.zeros((7500, 1430))\n",
    "thia_collected_preprocessed[0:2500] = thia_batch1_3min_mapping[:, 170:]\n",
    "thia_collected_preprocessed[2500:5000] = thia_batch2_3min_mapping[:, 170:]\n",
    "thia_collected_preprocessed[5000:] = thia_batch3_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thia_collected_preprocessed = rpd.remove_cosmic_rays(thia_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(car_collected_preprocessed)):\n",
    "    plt.plot(f_sup, thia_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aceta_collected_preprocessed = np.zeros((7500, 1430))\n",
    "aceta_collected_preprocessed[0:2500] = aceta_batch1_3min_mapping[:, 170:]\n",
    "aceta_collected_preprocessed[2500:5000] = aceta_batch2_3min_mapping[:, 170:]\n",
    "aceta_collected_preprocessed[5000:] = aceta_batch3_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aceta_collected_preprocessed = rpd.remove_cosmic_rays(aceta_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(car_collected_preprocessed)):\n",
    "    plt.plot(f_sup, aceta_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_thia_collected_preprocessed = np.zeros((7500, 1430))\n",
    "car_thia_collected_preprocessed[0:2500] = car_thia_batch1_3min_mapping[:, 170:]\n",
    "car_thia_collected_preprocessed[2500:5000] = car_thia_batch2_3min_mapping[:, 170:]\n",
    "car_thia_collected_preprocessed[5000:] = car_thia_batch3_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_thia_collected_preprocessed = rpd.remove_cosmic_rays(car_thia_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(car_collected_preprocessed)):\n",
    "    plt.plot(f_sup, car_thia_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f_sup, np.mean(car_thia_collected_preprocessed, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_aceta_collected_preprocessed = np.zeros((7500, 1430))\n",
    "car_aceta_collected_preprocessed[0:2500] = car_aceta_batch1_3min_mapping[:, 170:]\n",
    "car_aceta_collected_preprocessed[2500:5000] = car_aceta_batch2_3min_mapping[:, 170:]\n",
    "car_aceta_collected_preprocessed[5000:] = car_aceta_batch3_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_aceta_collected_preprocessed = rpd.remove_cosmic_rays(car_aceta_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(car_collected_preprocessed)):\n",
    "    plt.plot(f_sup, car_aceta_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thia_aceta_collected_preprocessed = np.zeros((7168, 1430))\n",
    "thia_aceta_collected_preprocessed[0:1024] = thia_aceta_batch1_3min_mapping[:, 170:]\n",
    "thia_aceta_collected_preprocessed[1024:2048] = thia_aceta_batch2_3min_mapping[:, 170:]\n",
    "thia_aceta_collected_preprocessed[2048:3072] = thia_aceta_batch3_3min_mapping[:, 170:]\n",
    "thia_aceta_collected_preprocessed[3072:4096] = thia_aceta_batch4_3min_mapping[:, 170:]\n",
    "thia_aceta_collected_preprocessed[4096:5120] = thia_aceta_batch5_3min_mapping[:, 170:]\n",
    "thia_aceta_collected_preprocessed[5120:6144] = thia_aceta_batch6_3min_mapping[:, 170:]\n",
    "thia_aceta_collected_preprocessed[6144:] = thia_aceta_batch7_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thia_aceta_collected_preprocessed = rpd.remove_cosmic_rays(thia_aceta_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(thia_aceta_collected_preprocessed)):\n",
    "    plt.plot(f_sup, thia_aceta_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 + 2 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_thia_aceta_collected_preprocessed = np.zeros((3072, 1430))\n",
    "car_thia_aceta_collected_preprocessed[0:1024] = car_thia_aceta_batch1_3min_mapping[:, 170:]\n",
    "car_thia_aceta_collected_preprocessed[1024:2048] = car_thia_aceta_batch2_3min_mapping[:, 170:]\n",
    "car_thia_aceta_collected_preprocessed[2048:] = car_thia_aceta_batch3_3min_mapping[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_thia_aceta_collected_preprocessed = rpd.remove_cosmic_rays(car_thia_aceta_collected_preprocessed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(car_thia_aceta_collected_preprocessed)):\n",
    "    plt.plot(f_sup, car_thia_aceta_collected_preprocessed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_all_cntr = np.zeros((25572, 1430))\n",
    "mg_all_cntr[0:2500] = mg_15000ppb_1[:, 170:]\n",
    "mg_all_cntr[2500:5000] = mg_15000ppb_2[:, 170:]\n",
    "mg_all_cntr[5000:7500] = mg_15000ppb_3[:, 170:]\n",
    "mg_all_cntr[7500:10000] = mg_15000ppb_4[:, 170:]\n",
    "mg_all_cntr[10000:12500] = mg_1500ppb_1[:, 170:]\n",
    "mg_all_cntr[12500:15000] = mg_1500ppb_2[:, 170:]\n",
    "mg_all_cntr[15000:17500] = mg_1500ppb_3[:, 170:]\n",
    "mg_all_cntr[17500:20000] = mg_1500ppb_4[:, 170:]\n",
    "mg_all_cntr[20000:22500] = mg_150ppb_1[:, 170:]\n",
    "mg_all_cntr[22500:23524] = mg_150ppb_2[:, 170:]\n",
    "mg_all_cntr[23524:24548] = mg_150ppb_3[:, 170:]\n",
    "mg_all_cntr[24548:] = mg_150ppb_4[:, 170:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_all_cntr = rpd.remove_cosmic_rays(mg_all_cntr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mg_all_cntr)):\n",
    "    plt.plot(f_sup[170:], mg_all_cntr[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all of the data in one big matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_dataset = np.zeros((73312, 1430))\n",
    "spectra_dataset[0:7500] = car_collected_preprocessed\n",
    "spectra_dataset[7500:15000] = thia_collected_preprocessed\n",
    "spectra_dataset[15000:22500] = aceta_collected_preprocessed\n",
    "spectra_dataset[22500:30000] = car_thia_collected_preprocessed\n",
    "spectra_dataset[30000:37500] = car_aceta_collected_preprocessed\n",
    "spectra_dataset[37500:44668] = thia_aceta_collected_preprocessed\n",
    "spectra_dataset[44668:47740] = car_thia_aceta_collected_preprocessed\n",
    "spectra_dataset[47740:] = mg_all_cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpd.store_data(spectra_dataset, \"clipped_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_dataset = rd.read_data(\"dataset.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = np.zeros((73312))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask[0:7500] = 1\n",
    "label_mask[7500:15000] = 2\n",
    "label_mask[15000:22500] = 3\n",
    "label_mask[22500:30000] = 4\n",
    "label_mask[30000:37500] = 5\n",
    "label_mask[37500:44668] = 6\n",
    "label_mask[44668:47740] = 7\n",
    "label_mask[47740:] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask[0:7500] = 1\n",
    "label_mask[7500:15000] = 2\n",
    "label_mask[15000:22500] = 3\n",
    "label_mask[22500:30000] = (1, 2)\n",
    "label_mask[30000:37500] = (1, 3)\n",
    "label_mask[37500:44668] = (2, 3)\n",
    "label_mask[44668:47740] = (1, 2, 3)\n",
    "label_mask[47740:] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = np.zeros((73312, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask[0:7500] = [1, 0, 0, 0]\n",
    "label_mask[7500:15000] = [0, 1, 0, 0]\n",
    "label_mask[15000:22500] = [0, 0, 1, 0]\n",
    "label_mask[22500:30000] = [1, 1, 0, 0]\n",
    "label_mask[30000:37500] = [1, 0, 1, 0]\n",
    "label_mask[37500:44668] = [0, 1, 1, 0]\n",
    "label_mask[44668:47740] = [1, 1, 1, 0]\n",
    "label_mask[47740:] = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_idx = np.where(np.sum(spectra_dataset, axis=1) != 0)\n",
    "non_zero_dataset = spectra_dataset[non_zero_idx]\n",
    "non_zero_label_mask = labels[non_zero_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove INF or NINF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_inf_idx = np.where(np.all(np.isfinite(non_zero_dataset), axis=-1) == True)[0]\n",
    "non_inf_dataset = non_zero_dataset[non_inf_idx]\n",
    "non_inf_label_mask = non_zero_label_mask[non_inf_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use sklearn normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spectra_dataset = normalize(non_inf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_spectra_dataset, non_inf_label_mask, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on 1 analyte (Can choose any of the analytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_collected_preprocessed = rpd.remove_zeros_or_nans(car_collected_preprocessed)\n",
    "n_components= 7\n",
    "model = PCA(n_components)\n",
    "W_PCA = model.fit_transform(norm_spectra_dataset)\n",
    "H_PCA = model.components_\n",
    "t_dataN_PCA = H_PCA\n",
    "f_dataN_PCA = W_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_values = np.arange(model.n_components_) + 1\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(PC_values, model.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(non_inf_label_mask == 8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"PCA analysis on Carbendazim\", figsize=(15, 10))\n",
    "plt.subplot(121)#, figsize = (15, 10))\n",
    "for i in range(n_components):\n",
    "    plt.plot((f_dataN_PCA[:,i]-min(f_dataN_PCA[:,i]))/np.mean(max(f_dataN_PCA[:,i])-min(f_dataN_PCA[:,i]))-i)\n",
    "plt.vlines(x=7500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=15000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=22500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=30000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=37500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=44188, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=47260, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.text(3250,1,\"1\")\n",
    "plt.text(10000,1,\"2\")\n",
    "plt.text(18000,1,\"4\")\n",
    "plt.text(25000,1,\"1+2\")\n",
    "plt.text(32000,1,\"1+4\")\n",
    "plt.text(40000,1,\"2+4\")\n",
    "plt.text(45000,1,\"1+2+4\")\n",
    "plt.text(60000,1,\"MG\")\n",
    "plt.show()\n",
    "plt.subplot(122)#, figsize=(15, 10))\n",
    "for i in range(n_components):\n",
    "    plt.plot(((t_dataN_PCA[i]-min(t_dataN_PCA[i]))/(max(t_dataN_PCA[i])-min(t_dataN_PCA[i]))-i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"PCA analysis on Carbendazim\", figsize=(15, 10))\n",
    "plt.subplot(121)#, figsize = (15, 10))\n",
    "for i in range(n_components):\n",
    "    plt.plot((f_dataN_PCA[:,i]-min(f_dataN_PCA[:,i]))/np.mean(max(f_dataN_PCA[:,i])-min(f_dataN_PCA[:,i]))-i)\n",
    "# plt.vlines(x=7500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=15000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=22500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=30000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=37500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=44188, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=47260, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.text(3250,1,\"1\")\n",
    "# plt.text(10000,1,\"2\")\n",
    "# plt.text(18000,1,\"4\")\n",
    "# plt.text(25000,1,\"1+2\")\n",
    "# plt.text(32000,1,\"1+4\")\n",
    "# plt.text(40000,1,\"2+4\")\n",
    "# plt.text(45000,1,\"1+2+4\")\n",
    "# plt.text(60000,1,\"MG\")\n",
    "# plt.show()\n",
    "plt.subplot(122)#, figsize=(15, 10))\n",
    "for i in range(n_components):\n",
    "    plt.plot(((t_dataN_PCA[i]-min(t_dataN_PCA[i]))/(max(t_dataN_PCA[i])-min(t_dataN_PCA[i]))-i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_mean = np.mean(car_collected_preprocessed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thia_mean = np.mean(thia_collected_preprocessed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_thia_mean = np.mean(car_thia_collected_preprocessed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(labels == [1., 0., 0., 0.])\n",
    "plt.plot(np.mean(norm_spectra_dataset[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_np = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(torch.allclose(torch.eq(labels, torch.tensor([1., 1., 1., 1.]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_1_norm = np.sqrt(sum(car_mean**2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_of_mix_on_1 = (np.dot(car_thia_mean, car_mean)/pure_1_norm**2)*car_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(proj_of_mix_on_1)\n",
    "plt.plot(car_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(W_PCA, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = classifier.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(classifier, new_data, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.5f accuracy with a standard deviation of %0.5f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"LDA analysis on dataset\", figsize=(15, 10))\n",
    "plt.subplot(121)#, figsize = (15, 10))\n",
    "for i in range(7):\n",
    "    plt.plot((f_dataN_LDA[:,i]-min(f_dataN_LDA[:,i]))/np.mean(max(f_dataN_LDA[:,i])-min(f_dataN_LDA[:,i]))-i)\n",
    "plt.vlines(x=7500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=15000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=22500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=30000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=37500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=44188, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.vlines(x=47260, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "plt.text(3250,1,\"1\")\n",
    "plt.text(10000,1,\"2\")\n",
    "plt.text(18000,1,\"4\")\n",
    "plt.text(25000,1,\"1+2\")\n",
    "plt.text(32000,1,\"1+4\")\n",
    "plt.text(40000,1,\"2+4\")\n",
    "plt.text(45000,1,\"1+2+4\")\n",
    "plt.text(60000,1,\"MG\")\n",
    "plt.show()\n",
    "plt.subplot(122)#, figsize=(15, 10))\n",
    "for i in range(n_components):\n",
    "    plt.plot(((t_dataN_LDA[i]-min(t_dataN_LDA[i]))/(max(t_dataN_LDA[i])-min(t_dataN_LDA[i]))-i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(norm_spectra_dataset, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "U, s, Vh = linalg.svd(norm_spectra_dataset, full_matrices=False, lapack_driver='gesvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(s[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"SVD analysis on dataset\", figsize=(15, 10))\n",
    "plt.subplot(121)#, figsize = (15, 10))\n",
    "for i in range(7):\n",
    "    plt.plot((Vh[i]*3) - i)\n",
    "# plt.vlines(x=7500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=15000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=22500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=30000, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=37500, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=44188, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# plt.vlines(x=47260, ymin=-5, ymax=1, colors=\"k\", linestyles=\"dashed\")\n",
    "# # plt.text(3250,1,\"1\")\n",
    "# plt.text(10000,1,\"2\")\n",
    "# plt.text(18000,1,\"4\")\n",
    "# plt.text(25000,1,\"1+2\")\n",
    "# plt.text(32000,1,\"1+4\")\n",
    "# plt.text(40000,1,\"2+4\")\n",
    "# plt.text(45000,1,\"1+2+4\")\n",
    "# plt.text(60000,1,\"MG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(7):\n",
    "    plt.plot(U.T[i]*50 - i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label Linear Disciminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The multi-label global mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class wise scatter matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class-wise betweem-class scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class-wise within-class scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class-wise total-class scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.zeros((73312, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:7500] = torch.tensor([1, 0, 0, 0.])\n",
    "labels[7500:15000] = torch.tensor([0, 1, 0, 0])\n",
    "labels[15000:22500] = torch.tensor([0, 0, 1, 0])\n",
    "labels[22500:30000] = torch.tensor([1, 1, 0, 0])\n",
    "labels[30000:37500] = torch.tensor([1, 0, 1, 0])\n",
    "labels[37500:44668] = torch.tensor([0, 1, 1, 0])\n",
    "labels[44668:47740] = torch.tensor([1, 1, 1, 0])\n",
    "labels[47740:] = torch.tensor([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_idx = np.where(np.sum(spectra_dataset, axis=1) != 0)\n",
    "labels = labels[non_zero_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_inf_idx = np.where(np.all(np.isfinite(non_zero_dataset), axis=-1) == True)[0]\n",
    "labels = labels[non_inf_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load, val_load, test_load = spectral_dataloaders(norm_spectra_dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = non_inf_dataset.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv1D(n_input, n_hidden),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv1D(),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool1d(),\n",
    "                      nn.Dropout(),\n",
    "                      nn.Conv1D(),\n",
    "                      nn.Conv1D(),\n",
    "                      nn.MaxPool1d(),\n",
    "                      nn.Dropout(),\n",
    "                      nn.Conv1D(),\n",
    "                      nn.Conv1D(),\n",
    "                      nn.MaxPool1d(),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(),\n",
    "                      nn.Linear(n_hidden, n_out),\n",
    "                      nn.Sigmoid())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For labels encoding use Multi Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For accuracy metrics use F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Loss function use Binary Cross Entropy with Logits  \n",
    "This loss tends to perform best for multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN parameters\n",
    "layers = 6\n",
    "hidden_size = 50\n",
    "block_size = 2\n",
    "hidden_sizes = [hidden_size] * layers\n",
    "num_blocks = [block_size] * layers\n",
    "input_dim = 1430\n",
    "in_channels = 64\n",
    "n_classes = 4\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(0)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained weights for demo\n",
    "cnn = ResNet(hidden_sizes, num_blocks, input_dim=input_dim,\n",
    "                in_channels=in_channels, n_classes=n_classes)\n",
    "\n",
    "# if cuda: \n",
    "cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import run_epoch\n",
    "from torch import optim\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = 0.1\n",
    "n_val = int(58224 * p_val)\n",
    "idx_tr = list(range(58224))\n",
    "np.random.shuffle(idx_tr)\n",
    "idx_val = idx_tr[:n_val]\n",
    "idx_tr = idx_tr[n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune CNN\n",
    "epochs = 1 # Change this number to ~30 for full training\n",
    "batch_size = 10\n",
    "t0 = time()\n",
    "# Set up Adam optimizer\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "# Set up dataloaders\n",
    "dl_tr = spectral_dataloader(X_train, y_train, idxs=idx_tr,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "dl_val = spectral_dataloader(X_train, y_train, idxs=idx_val,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "dl_test = spectral_dataloader(X_test, y_test, batch_size=10, shuffle=False)\n",
    "# Fine-tune CNN for first fold\n",
    "best_val = 0\n",
    "no_improvement = 0\n",
    "max_no_improvement = 5\n",
    "print('Starting fine-tuning!')\n",
    "for epoch in range(epochs):\n",
    "    print(' Epoch {}: {:0.5f}s'.format(epoch+1, time()-t0))\n",
    "    # Train\n",
    "    acc_tr, loss_tr, acccc_tr, lossss_tr = run_epoch(epoch, cnn, dl_tr, cuda,\n",
    "        training=True, optimizer=optimizer)\n",
    "    print('  Train acc: {:0.5f}'.format(acc_tr))\n",
    "    # Val\n",
    "    acc_val, loss_val, acccc_val, lossss_val = run_epoch(epoch, cnn, dl_val, cuda,\n",
    "        training=False, optimizer=optimizer)\n",
    "    print('  Val acc  : {:0.5f}'.format(acc_val))\n",
    "    # Check performance for early stopping\n",
    "    if acc_val > best_val or epoch == 0:\n",
    "        \n",
    "        best_val = acc_val\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    if no_improvement >= max_no_improvement:\n",
    "        print('Finished after {} epochs!'.format(epoch+1))\n",
    "        break\n",
    "\n",
    "print('\\n This demo was completed in: {:0.2f}s'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acccc_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(acccc_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossss_tr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(lossss_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import get_predictions\n",
    "# from spectral_datasets import spectral_dataloader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on subset of data\n",
    "t0 = time()\n",
    "# dl = spectral_dataloader(X, y, batch_size=10, shuffle=False)\n",
    "y_hat = get_predictions(cnn, dl_test, cuda, get_probs = True)\n",
    "print('Predicted {} spectra: {:0.5f}s'.format(len(y_hat), time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing accuracy\n",
    "# acc = (y_hat == y).mean()\n",
    "acc = f1_score((y_hat > 0.6).astype(int), y_test.detach().cpu().numpy().astype(int), average='macro')\n",
    "print('Accuracy: {:0.5f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on synthetic data\n",
    "The result should go to last label.  \n",
    "This data was not used during training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_aug(y_data: np.ndarray, amp: float):\n",
    "    \"\"\"\n",
    "    Adds gaussian noise to the spectrum in direction of its variance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data : np.ndarray\n",
    "        Y data. A spectrum.\n",
    "    amp : float\n",
    "        A percentage given as a decimal. Strength of noise.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Spectrum plus noise.\n",
    "\n",
    "    \"\"\"    \n",
    "    #adding noise to the spectrum\n",
    "    n = np.random.normal(0, y_data.std(), y_data.shape[-1]) * amp\n",
    "    return y_data + n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = noise_aug(X_test, amp=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test_noisy[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test_noisy = spectral_dataloader(X_test_noisy, y_test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on subset of data\n",
    "t0 = time()\n",
    "# dl = spectral_dataloader(X, y, batch_size=10, shuffle=False)\n",
    "y_hat = get_predictions(cnn, dl_test_noisy, cuda, get_probs = True)\n",
    "print('Predicted {} spectra: {:0.5f}s'.format(len(y_hat), time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.detach().cpu().numpy()\n",
    "# Computing accuracy\n",
    "# acc = (y_hat == y).mean()\n",
    "acc = f1_score((y_hat > 0.6).astype(int), y_test.detach().cpu().numpy().astype(int), average='macro')\n",
    "print('Accuracy: {:0.5f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SyntheticSignal import Synthetic_Signal as synsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(params, add_peak, shuffle=False):\n",
    "    dat = list()\n",
    "    piks = list()\n",
    "    for i in range(len(params['smu'])):\n",
    "        siegs = synsi.Synthetic_Signal()\n",
    "        siegs.generate_random_walk(N=params['N'], batch_size=params['batch_size'],\n",
    "                                   mu=params['smu'][i],sigma=params['ssig'][i],\n",
    "                                   reverse=params['reverse'][i], seed=params['sid'][i])\n",
    "        siegs.smooth_data()\n",
    "        if(add_peak[i]):\n",
    "            siegs.r_add_peak(fwhmG=params['fwhmG'][i], fwhmL=params['fwhmL'][i],\n",
    "                             amplitudeL=params['pa'][i])\n",
    "            piks.append([siegs.peak[i].x_0[0] for i in range(siegs.batch_size)])\n",
    "        else:\n",
    "            piks.append([0 for i in range(siegs.batch_size)])\n",
    "        siegs.add_noise(mu=params['nmu'][i], sigma=params['nsig'][i],\n",
    "                        a=params['na'][i])\n",
    "        dat.append(siegs.data)\n",
    "    peaks = np.concatenate((piks[0], piks[1], piks[2], piks[3]), axis=0)\n",
    "    dataset = np.concatenate((dat[0], dat[1], dat[2], dat[3]), axis=0)\n",
    "    #if(shuffle):\n",
    "        \n",
    "    return dataset, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'N':1430, 'batch_size':30, 'smu':[0, 0, 1, 2], 'ssig':[1, 2, 0.5, 1],\n",
    "          'reverse':[True, False, True, True], 'sid':[21, 13, 15, 24],\n",
    "          'fwhmG':[53, 25, 32, 45], 'fwhmL':[15, 10, 5, 21], 'pa':[0.9, 0.6, 0.5, 1],\n",
    "          'nmu':[0, 0, 0, 0], 'nsig':[1, 1, 1, 1], 'na':[0.03, 0.06, 0.09, 0.12]}\n",
    "\n",
    "add_peak = [True, True, False, True]\n",
    "\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, peak_locs = create_dataset(params, add_peak, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_synthetic = torch.zeros((120, 4))\n",
    "labels_synthetic[:] = torch.tensor([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_synthetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test_synthetic = spectral_dataloader(dataset, labels_synthetic, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on subset of data\n",
    "t0 = time()\n",
    "# dl = spectral_dataloader(X, y, batch_size=10, shuffle=False)\n",
    "y_hat = get_predictions(cnn, dl_test_synthetic, cuda, get_probs = True)\n",
    "print('Predicted {} spectra: {:0.5f}s'.format(len(y_hat), time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_synthetic.detach().cpu().numpy()\n",
    "# Computing accuracy\n",
    "# acc = (y_hat == y).mean()\n",
    "acc = f1_score((y_hat > 0.6).astype(int), labels_synthetic.detach().cpu().numpy().astype(int), average='macro')\n",
    "print('Accuracy: {:0.5f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
